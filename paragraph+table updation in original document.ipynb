{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e95f85ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docx import Document\n",
    "#import docx\n",
    "#mydoc=Document()\n",
    "#def get_data_from_word(path):\n",
    "    #doc_object=open(path,'rb')\n",
    "    #doc_reader=Document(doc_object)\n",
    "    #data=\" \"\n",
    "    #for p in doc_reader.paragraphs:\n",
    "        #data+=p.text+ '\\n'\n",
    "    #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac183bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_file=r\"C:/Users/Shubham/Desktop/Data Scientist.docx\"\n",
    "#text=get_data_from_word(path_to_file)\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54ab8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#sentences=nltk.sent_tokenize(text)\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a16a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2022 12:30:20 - INFO - happytransformer.happy_transformer -   Using model: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText,TTSettings\n",
    "happy=HappyTextToText(\"T5\",'t5-base',r\"C:\\Users\\Shubham\\Downloads\\gm_model-20220609T071856Z-001\\gm_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4dd94d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_settings=TTSettings(num_beams=3,min_length=0,max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5e82230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_={}\n",
    "#import nltk\n",
    "#for table in doc.tables:\n",
    "    #for row in table.rows:\n",
    "        #for cell in row.cells:\n",
    "            #for paragraph in cell.paragraphs:\n",
    "                #data=nltk.sent_tokenize(paragraph.text)\n",
    "                #for sent in data:\n",
    "                    #result_1=happy.generate_text(\"grammar: \"+sent,args=beam_settings)\n",
    "                    #dict_.update({sent:result_1.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "704cb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9474bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for table in doc.tables:\n",
    "    #for row in table.rows:\n",
    "        #for cell in row.cells:\n",
    "            #for paragraph in cell.paragraphs:\n",
    "                #inline=paragraph.runs\n",
    "                #for i in range(len(inline)):\n",
    "                    #text=inline[i].text\n",
    "                    #for key,value in dict_.items():\n",
    "                        #if key in text:\n",
    "                            #text=text.replace(key,dict_[value])\n",
    "                            #inline[i].text=text\n",
    "                            \n",
    "#path=\"C:/Users/Shubham/Downloads/\"\n",
    "#doc.save(path+'Fresh_6.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f761e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=Document(r\"C:/Users/Shubham/Desktop/Data Scientist.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10ed7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking model prediction on paragraph text and table text and updating it into a dictionary.\n",
    "dict_={}\n",
    "def grammar_model(sentences):\n",
    "    #Accessing paragraph text\n",
    "    for para in doc.paragraphs:\n",
    "        data=nltk.sent_tokenize(para.text)\n",
    "        for i,sent in enumerate(data):\n",
    "            result=happy.generate_text(\"grammar: \"+sent,args=beam_settings)\n",
    "            if data[i]==result.text:\n",
    "                continue\n",
    "            else:\n",
    "                dict_.update({sent:result.text})\n",
    "    # accessing table text \n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                for paragraph in cell.paragraphs:\n",
    "                    data=nltk.sent_tokenize(paragraph.text)\n",
    "                    for sent in data:\n",
    "                        result=happy.generate_text(\"grammar: \"+sent,args=beam_settings)\n",
    "                        dict_.update({sent:result.text})\n",
    "grammar_corrected_sentences=grammar_model(sentences)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5db8e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I belong to Delhi.': 'i belong to delhi',\n",
       " 'I did my graduation from Delhi University.': 'i did my graduation from delhi university',\n",
       " 'After that I taught statistics and simultaneously, I was preparing for Data Scientist role as well.': 'after that i taught statistics and simultaneously i was preparing for a data scientist role as well',\n",
       " 'Right now I am working as a junior Data Scientist.': 'Right now I am working as a junior data scientist',\n",
       " 'Data Science': 'data science',\n",
       " 'Statistics': 'Statistics',\n",
       " 'Data science leverages the power of Data, Mathematics, and computer programming.': 'Data science leverages the power of data mathematics and computer programming',\n",
       " 'Statistics is a branch of mathematics which is used to built predictive model.': 'Statistics is a branch of mathematics which is used to build a predictive model.',\n",
       " 'Data science is much more advance.': 'data science is much more advanced.',\n",
       " 'We can use statistics for smaller data set.': 'we can use statistics for a smaller data set.',\n",
       " 'Data science evolved recently.': 'data science evolved recently.',\n",
       " 'Statistics is in used for a long time.': 'Statistics are in use for a long time.'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0e4554bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "doc=Document(r\"C:/Users/Shubham/Desktop/Data Scientist.docx\")\n",
    "\n",
    "# Updating grammar corrected sentences in original document paragraph.\n",
    "for p in doc.paragraphs:\n",
    "    inline = p.runs\n",
    "    for i in range(len(inline)):\n",
    "        text = inline[i].text\n",
    "        for key in dict_.keys():\n",
    "            if key in text:\n",
    "                text=text.replace(key,dict_[key])\n",
    "                inline[i].text = text\n",
    "#Updating grammar corrected sentences in original document tables.                   \n",
    "for table in doc.tables:\n",
    "    for row in table.rows:\n",
    "        for cell in row.cells:\n",
    "            for paragraph in cell.paragraphs:\n",
    "                inline=paragraph.runs\n",
    "                for i in range(len(inline)):\n",
    "                    text=inline[i].text\n",
    "                    for key in dict_.keys():\n",
    "                        if key in text:\n",
    "                            text=text.replace(key,dict_[key])\n",
    "                            inline[i].text=text\n",
    "\n",
    "path=\"C:/Users/Shubham/Downloads/\"\n",
    "doc.save(path+'Fresh_12.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecd59713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from docx import Document\n",
    "#doc=Document(r\"C:/Users/Shubham/Desktop/Data Scientist.docx\")\n",
    "\n",
    "#class Sentence_Replacement:\n",
    "    #def __init__(self,data):\n",
    "        #self.data=data\n",
    "        \n",
    "    #def para_replacement(self):\n",
    "        #for p in self.data.paragraphs:\n",
    "            #inline = p.runs\n",
    "            #for i in range(len(inline)):\n",
    "                #text = inline[i].text\n",
    "                #for key in dict_.keys():\n",
    "                    #if key in text:\n",
    "                        #text=text.replace(key,dict_[key])\n",
    "                        #inline[i].text = text\n",
    "                        \n",
    "    #def table_replacement(self):\n",
    "        #for table in self.data.tables:\n",
    "            #for row in table.rows:\n",
    "                #for cell in row.cells:\n",
    "                    #for paragraph in cell.paragraphs:\n",
    "                        #inline=paragraph.runs\n",
    "                        #for i in range(len(inline)):\n",
    "                            #text=inline[i].text\n",
    "                            #for key,value in dict_.items():\n",
    "                                #if key in text:\n",
    "                                    #text=text.replace(key,dict_[key])\n",
    "                                    #inline[i].text=text\n",
    "                        \n",
    "                        \n",
    "#res=Sentence_Replacement(doc)\n",
    "#print(res.para_replacement())\n",
    "#print(res.table_replacement()) \n",
    "\n",
    "#path=\"C:/Users/Shubham/Downloads/\"\n",
    "#doc.save(path+'Fresh_15.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058ad4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
