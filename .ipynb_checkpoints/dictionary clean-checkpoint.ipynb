{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f920f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text= \"Ashwanth Ash ashu as\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc3232eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Ash ashu  '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=re.sub(r'\\b(\\w{1,2}|\\w{5,})\\b', ' ', text)#remove words lesthan 3\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9002f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from docx import Document\n",
    "import docx\n",
    "import re\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_lg\n",
    "from rapidfuzz import fuzz, process\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 38488877\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97e7f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = open('special_characters.txt', 'r', encoding='utf-8')\n",
    "char_list = char_list.read()\n",
    "char_list=char_list.split(\"\\n\")\n",
    "char_list=np.array(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "277dbf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ash='I am ashwanth@lonely.com'\n",
    "ashu=' '.join([ele for ele in ash.split(' ') if all(ch not in ele for ch in char_list)])# new code line to remove special character words\n",
    "ashu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fcb0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = open('Stopword.txt', 'r', encoding='utf-8')\n",
    "Stopwords = Stopwords.read()\n",
    "Stopwords=Stopwords.split(\"\\n\")\n",
    "Stopwords=np.array(Stopwords)\n",
    "#Stopwords=np.array(Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86bc21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define document importing path\n",
    "def get_data_from_word(path_to_file):\n",
    "    doc_object=open(path_to_file, \"rb\")\n",
    "    doc_reader=Document(doc_object)\n",
    "    data=\" \"\n",
    "    for p in doc_reader.paragraphs:\n",
    "        data +=p.text+\"\\n\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc=get_data_from_word('C:/Users/chenn/Desktop/webspellings.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a94d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(text):\n",
    "    \n",
    "    text=' '.join(list(set(text.split(' '))))\n",
    "    text=' '.join([ele for ele in text.split(' ') if all(ch not in ele for ch in char_list)])# new code line to remove special character words\n",
    "    text=re.sub(r\"[^\\w'\\w]\",\" \",text)#remove all special characters except \"'\"\n",
    "    text=re.sub(r'\\S+[A-Z]\\S+|\\S+[A-Z]', \" \", text)#remove words with capitals in between new code\n",
    "        \n",
    "    text=re.sub(\"'$\", \" \", text)\n",
    "    text=re.sub(\"^'\", \" \", text)\n",
    "    text=re.sub('\\s+', ' ', text)#remove extra spaces\n",
    "    text=' '.join([i for i in text.lower().split(\" \") if len(i) > 2])\n",
    "    text=[word for word in text.lower().split(\" \") if word not in Stopwords]#remove stop words\n",
    "    while '' in text:\n",
    "        text.remove('')\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508af473",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_text=Clean(Doc) #clean Document\n",
    "clean_text=list(dict.fromkeys(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b4976",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookups=[w for w in clean_text if len(w)>4]\n",
    "lookups1=[w for w in clean_text if len(w)<5 and len(w)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "UTC=pytz.utc\n",
    "IST=pytz.timezone('Asia/Kolkata')\n",
    "dt=datetime.datetime.now(IST)\n",
    "dt2=t_string=dt.strftime(\"%d-%m-%y\")\n",
    "len(lookups1+lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615be3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()\n",
    "document.add_paragraph(doc)\n",
    "\n",
    "document.save(f'C:/Users/chenn/Desktop/clean2{dt2}.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath='C:/Users/chenn/Desktop/'\n",
    "df=pd.DataFrame(lookups1+lookups)\n",
    "df.to_csv(outputpath+f'missing on 2{dt2}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55543757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
