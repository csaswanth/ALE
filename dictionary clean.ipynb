{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f920f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text= \"Ashwanth Ash ashu as\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc3232eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Ash ashu  '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=re.sub(r'\\b(\\w{1,2}|\\w{5,})\\b', ' ', text)#remove words lesthan 3\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9002f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from docx import Document\n",
    "import docx\n",
    "import re\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import en_core_web_lg\n",
    "from rapidfuzz import fuzz, process\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 38488877\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e7f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_list = open('special_characters.txt', 'r', encoding='utf-8')\n",
    "char_list = char_list.read()\n",
    "char_list=char_list.split(\"\\n\")\n",
    "char_list=np.array(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b521ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ash='I am ashwanth@lonely.com'\n",
    "ashu=' '.join([ele for ele in ash.split(' ') if all(ch not in ele for ch in char_list)])# new code line to remove special character words\n",
    "ashu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcb0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stopwords = open('Stopword.txt', 'r', encoding='utf-8')\n",
    "Stopwords = Stopwords.read()\n",
    "Stopwords=Stopwords.split(\"\\n\")\n",
    "Stopwords=np.array(Stopwords)\n",
    "#Stopwords=np.array(Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bc21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define document importing path\n",
    "def get_data_from_word(path_to_file):\n",
    "    doc_object=open(path_to_file, \"rb\")\n",
    "    doc_reader=Document(doc_object)\n",
    "    data=\" \"\n",
    "    for p in doc_reader.paragraphs:\n",
    "        data +=p.text+\"\\n\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69e5282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path='C:/Users/chenn/Desktop/gp/'\n",
    "filename='For spellcheck1'\n",
    "Doc=get_data_from_word(path+filename+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c89e73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24964"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a94d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clean(text):\n",
    "    \n",
    "    text=' '.join(list(set(text.split(' '))))#\n",
    "    text=' '.join([ele for ele in text.split(' ') if all(ch not in ele for ch in char_list)])# new code line to remove special character words\n",
    "    text=re.sub(r\"[^\\w'\\w|-]\",\" \",text)#remove all special characters except \"'\"\n",
    "    text=re.sub(r'\\S+[A-Z]\\S+|\\S+[A-Z]', \" \", text)#remove words with capitals in between new code\n",
    "    text=re.sub(\"'$\", \" \", text)#remove apporstaphies from end of text\n",
    "    text=re.sub(\"^'\", \" \", text)#remove apporstaphies from beginningof text\n",
    "\n",
    "    text=re.sub('\\s+', ' ', text)#remove extra spaces\n",
    "    text=re.sub('\\n+', ' ', text)# remove extra line spaces\n",
    "    text=' '.join([i for i in text.split(\" \") if len(i) > 2])\n",
    "    text=[word for word in text.lower().split(\" \") if word not in Stopwords]#remove stop words\n",
    "    \"\"\"while '' in text:\n",
    "        text.remove('')\"\"\"\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508af473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_text=Clean(Doc) #clean Document\n",
    "clean_text=list(dict.fromkeys(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d06597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sgoifo',\n",
       " 'anmal',\n",
       " 'eevaluated',\n",
       " 'crowdding',\n",
       " 'consquences',\n",
       " 'senssory',\n",
       " 'defence',\n",
       " 'argbitrary',\n",
       " 'moddels',\n",
       " 'mday',\n",
       " 'bhavioral',\n",
       " 'thsese',\n",
       " 'weaks',\n",
       " 'invdolve',\n",
       " 'behaviours',\n",
       " 'wozuld',\n",
       " 'stredss',\n",
       " 'studins',\n",
       " 'vbiew',\n",
       " 'subordsinates',\n",
       " 'generaal',\n",
       " 'mekan',\n",
       " 'reprevsented',\n",
       " 'restrgaint',\n",
       " 'evhents',\n",
       " 'imspact',\n",
       " 'laboraory',\n",
       " 'hypothalmic-pituitary-gonaadal',\n",
       " 'winnners',\n",
       " 'defeeat',\n",
       " 'eeffects',\n",
       " 'loosers',\n",
       " 'examin',\n",
       " 'effcts',\n",
       " 'showen',\n",
       " 'funtioning',\n",
       " 'concetualized',\n",
       " 'includez',\n",
       " 'influenes',\n",
       " 'characterise',\n",
       " 'hypothalamic-pituiteary-gonadal',\n",
       " 'indivdiduals',\n",
       " 'phrmacological',\n",
       " 'bartolomucci',\n",
       " 'codntrast',\n",
       " 'psychopathologies',\n",
       " 'fiebld',\n",
       " 'redsponse',\n",
       " 'godbout',\n",
       " 'strengh',\n",
       " 'circumsxtances',\n",
       " 'technicques',\n",
       " 'regulatiwon',\n",
       " 'expnected',\n",
       " 'wdounding',\n",
       " 'contradictgory',\n",
       " 'varyant',\n",
       " 'labelled',\n",
       " 'tennd',\n",
       " 'situgation',\n",
       " 'shnown',\n",
       " 'situsation',\n",
       " 'defweat',\n",
       " 'scial',\n",
       " 'blofod',\n",
       " 'shock-probe',\n",
       " 'physiologicsal',\n",
       " 'strhessors',\n",
       " 'handley',\n",
       " 'intrducing',\n",
       " 'mofdeled',\n",
       " 'isolaetion',\n",
       " 'decrdease',\n",
       " 'depraivation',\n",
       " 'becouse',\n",
       " 'posivtion',\n",
       " 'padgett',\n",
       " 'exhdaustion',\n",
       " 'differentiatsion',\n",
       " 'intrudder',\n",
       " 'glaser',\n",
       " 'csolony',\n",
       " 'blanchard',\n",
       " 'behavdior',\n",
       " 'keywards',\n",
       " 'aggrssion',\n",
       " 'gallo',\n",
       " 'selefcted',\n",
       " 'exxperience',\n",
       " 'suboordinate',\n",
       " 'reljatively',\n",
       " 'biobehavioral',\n",
       " 'casses',\n",
       " 'onne',\n",
       " 'achiedved',\n",
       " 'ofen',\n",
       " 'studaies',\n",
       " 'concomitantss',\n",
       " 'predictaeble',\n",
       " 'effectvs',\n",
       " 'sfuch',\n",
       " 'resiadent',\n",
       " 'peeple',\n",
       " 'scocial',\n",
       " 'socdial',\n",
       " 'hogusing',\n",
       " 'impoortant',\n",
       " 'withingroup',\n",
       " 'domsticated',\n",
       " 'ddurationdependent',\n",
       " 'hrmone',\n",
       " 'tersms',\n",
       " 'finaly',\n",
       " 'hypothalamick',\n",
       " 'duratin',\n",
       " 'acbove',\n",
       " 'revleasingg',\n",
       " 'luteinising',\n",
       " 'mtabolic',\n",
       " 'oestrogens',\n",
       " 'stressoors',\n",
       " 'withinsex',\n",
       " 'anxiety-like',\n",
       " 'modxels',\n",
       " 'almsost',\n",
       " 'meansured',\n",
       " 'differdences',\n",
       " 'apprdoach',\n",
       " 'protocoles',\n",
       " 'respone',\n",
       " 'proxnimity',\n",
       " 'expserisenced',\n",
       " 'additizonal',\n",
       " 'encounteer',\n",
       " 'naiive',\n",
       " 'zsocial',\n",
       " 'oppossed',\n",
       " 'recurrrent',\n",
       " 'bariers',\n",
       " 'selfgrooming',\n",
       " 'brodly',\n",
       " 'quicfkly',\n",
       " 'ownn',\n",
       " 'theese',\n",
       " 'sociial',\n",
       " 'fvor',\n",
       " 'utilise',\n",
       " 'complexe',\n",
       " 'fieldd',\n",
       " 'sufbjects',\n",
       " 'stres',\n",
       " 'anmals',\n",
       " 'procehdure',\n",
       " 'exposufre',\n",
       " 'mhagnitude',\n",
       " 'exposur',\n",
       " 'othaers',\n",
       " 'consditions',\n",
       " 'hormfonal',\n",
       " 'resdidentintruder',\n",
       " 'recefived',\n",
       " 'ghaed',\n",
       " 'qualitvatively',\n",
       " 'incdices',\n",
       " 'aetiology',\n",
       " 'develped',\n",
       " 'whergeas',\n",
       " 'stremss',\n",
       " 'oetiology',\n",
       " 'endsocrine',\n",
       " 'drug-taking',\n",
       " 'victbory',\n",
       " 'disuption',\n",
       " 'individdual',\n",
       " 'adjaccent',\n",
       " 'insftability',\n",
       " 'roozendaal',\n",
       " 'magnsitude',\n",
       " 'axnimals',\n",
       " 'lifhe',\n",
       " 'beehaviours',\n",
       " 'produuces',\n",
       " 'tamashiro',\n",
       " 'stsructure',\n",
       " 'physsical',\n",
       " 'sedtting',\n",
       " 'chemiccal',\n",
       " 'nepomnaschy',\n",
       " 'preeexisting',\n",
       " 'chroic',\n",
       " 'moderatel',\n",
       " 'commone',\n",
       " 'behaviral',\n",
       " 'gsroup',\n",
       " 'variagbility',\n",
       " 'dominantt',\n",
       " 'invodlving',\n",
       " 'femaless',\n",
       " 'disrubtion',\n",
       " 'stress-relatd',\n",
       " 'procedoure',\n",
       " 'witth',\n",
       " 'attemt',\n",
       " 'whcile',\n",
       " 'stresss',\n",
       " 'laboratorey',\n",
       " 'stressrelated',\n",
       " 'powrful',\n",
       " 'pro-found',\n",
       " 'nstable',\n",
       " 'folalicle-stimulating',\n",
       " 'frvom',\n",
       " 'subgect',\n",
       " 'dominantsubordinate',\n",
       " 'exposurses',\n",
       " 'experieenced',\n",
       " 'ordeer',\n",
       " 'feeture',\n",
       " 'intermmittent',\n",
       " 'aggrevssive',\n",
       " 'reltionships',\n",
       " 'stressers',\n",
       " 'typiacally',\n",
       " 'interactios',\n",
       " 'halasz',\n",
       " 'gonadotropine',\n",
       " 'caage',\n",
       " 'connsequences',\n",
       " 'thdat',\n",
       " 'interraction',\n",
       " 'haller',\n",
       " 'incoorporating',\n",
       " 'kessler',\n",
       " 'experaience',\n",
       " 'crowgding',\n",
       " 'supgpression',\n",
       " 'crgowding',\n",
       " 'afor',\n",
       " 'chrodnic',\n",
       " 'palanza',\n",
       " 'post-traumatic',\n",
       " 'effcects',\n",
       " 'pychosocial',\n",
       " 'figghting',\n",
       " 'gruneberg',\n",
       " 'svocial',\n",
       " 'fsrom',\n",
       " 'stressresponsive',\n",
       " 'skhould',\n",
       " 'colonyies',\n",
       " 'differrent',\n",
       " 'homve',\n",
       " 'defeted',\n",
       " 'impeaired',\n",
       " 'neuarogenesis',\n",
       " 'norepinephrin',\n",
       " 'sertonin',\n",
       " 'strss',\n",
       " 'encoounters',\n",
       " 'dnumber',\n",
       " 'disdputes',\n",
       " 'betweeen',\n",
       " 'associavted',\n",
       " 'polabrized',\n",
       " 'estaablish',\n",
       " 'tesosterone',\n",
       " 'steeroid',\n",
       " 'stdress',\n",
       " 'glossery',\n",
       " 'behaviodrs',\n",
       " 'ramachandruni',\n",
       " 'behavioors',\n",
       " 'stzudies',\n",
       " 'additionn',\n",
       " 'dohrenwend',\n",
       " 'frquently',\n",
       " 'defveat',\n",
       " 'nonscuppression',\n",
       " 'nrmal',\n",
       " 'stresssful',\n",
       " 'subxject',\n",
       " 'whavt',\n",
       " 'involvses',\n",
       " 'intermitttent',\n",
       " 'natusral',\n",
       " 'divhiding',\n",
       " 'suboardinate',\n",
       " 'betweenc',\n",
       " 'odver']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "589ebbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8bcc31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookups=[w for w in clean_text if len(w)>4]#words >4 chars\n",
    "lookups1=[w for w in clean_text if len(w)<5 and len(w)>2]#words between 5 and 2 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "36bb7b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5402"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "UTC=pytz.utc\n",
    "IST=pytz.timezone('Asia/Kolkata')\n",
    "dt=datetime.datetime.now(IST)\n",
    "dt2=t_string=dt.strftime(\"%d-%m-%y,%H%M%S\")\n",
    "len(lookups1+lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a92ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath='C:/Users/chenn/Desktop/wbmissing/'\n",
    "df=pd.DataFrame(lookups1+lookups)#create data frame for missing words\n",
    "df.to_csv(outputpath+f'{filename}.csv')#save missing words in dictionary with date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "034f6125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ucak',\n",
       " 'ohno',\n",
       " 'sahi',\n",
       " 'kidd',\n",
       " 'covi',\n",
       " 'elie',\n",
       " 'arce',\n",
       " 'wahl',\n",
       " 'agam',\n",
       " 'teno',\n",
       " 'bilt',\n",
       " 'fuso',\n",
       " 'sved',\n",
       " 'vaag',\n",
       " 'orza',\n",
       " 'tati',\n",
       " 'ofek',\n",
       " 'muco',\n",
       " 'oude',\n",
       " 'und',\n",
       " 'hotz',\n",
       " 'ryff',\n",
       " 'weil',\n",
       " 'shao',\n",
       " 'hds',\n",
       " 'xaa',\n",
       " 'revy',\n",
       " 'diav',\n",
       " 'hyg',\n",
       " 'tato',\n",
       " 'bedi',\n",
       " 'kusy',\n",
       " 'kolb',\n",
       " 'gher',\n",
       " 'nah',\n",
       " 'nery',\n",
       " 'pini',\n",
       " 'sanz',\n",
       " 'sasi',\n",
       " 'paez',\n",
       " 'blum',\n",
       " 'yoon',\n",
       " 'liu',\n",
       " 'kato',\n",
       " 'lund',\n",
       " 'sein',\n",
       " 'ryan',\n",
       " 'hamp',\n",
       " 'ahn',\n",
       " 'aust',\n",
       " 'iker',\n",
       " 'dahl',\n",
       " 'roth',\n",
       " 'mik',\n",
       " 'lexi',\n",
       " 'kaye',\n",
       " 'roos',\n",
       " 'kot',\n",
       " 'treg',\n",
       " 'zhou',\n",
       " 'lara',\n",
       " 'jahn',\n",
       " 'netw',\n",
       " 'heij',\n",
       " 'lal',\n",
       " 'jang',\n",
       " 'hess',\n",
       " 'bez',\n",
       " 'leib',\n",
       " 'raju',\n",
       " 'chim',\n",
       " 'cmax',\n",
       " 'jens',\n",
       " 'lado',\n",
       " 'quik',\n",
       " 'kuo',\n",
       " 'gehr',\n",
       " 'miwa',\n",
       " 'como',\n",
       " 'toth',\n",
       " 'dige',\n",
       " 'aass',\n",
       " 'suei',\n",
       " 'laat',\n",
       " 'zhao',\n",
       " 'khoo',\n",
       " 'ngan',\n",
       " 'kaku',\n",
       " 'kase',\n",
       " 'endo',\n",
       " 'niu',\n",
       " 'zarb',\n",
       " 'aksu',\n",
       " 'asai',\n",
       " 'azam',\n",
       " 'bucy',\n",
       " 'amre',\n",
       " 'nuki',\n",
       " 'cenk',\n",
       " 'ohle',\n",
       " 'scaf',\n",
       " 'zilm',\n",
       " 'zhi',\n",
       " 'hinz',\n",
       " 'scx',\n",
       " 'nurs',\n",
       " 'krug',\n",
       " 'kahn',\n",
       " 'lepp',\n",
       " 'blut',\n",
       " 'diaz',\n",
       " 'bosy',\n",
       " 'tira',\n",
       " 'ando',\n",
       " 'irus',\n",
       " 'kois',\n",
       " 'heiv',\n",
       " 'opin',\n",
       " 'jemt',\n",
       " 'joos',\n",
       " 'metz',\n",
       " 'rimm',\n",
       " 'dagg',\n",
       " 'cifu',\n",
       " 'mei',\n",
       " 'nur',\n",
       " 'loeb',\n",
       " 'oteo',\n",
       " 'gde',\n",
       " 'nagy',\n",
       " 'baig',\n",
       " 'krok',\n",
       " 'haus',\n",
       " 'iwai',\n",
       " 'solu',\n",
       " 'rapp',\n",
       " 'kgp',\n",
       " 'roze',\n",
       " 'ethn',\n",
       " 'annu',\n",
       " 'olin',\n",
       " 'helv',\n",
       " 'cdos',\n",
       " 'lohr',\n",
       " 'ltd',\n",
       " 'nunn',\n",
       " 'gow',\n",
       " 'rae',\n",
       " 'vasc',\n",
       " 'dann',\n",
       " 'rech',\n",
       " 'mori',\n",
       " 'ther',\n",
       " 'felo',\n",
       " 'weng',\n",
       " 'azzi',\n",
       " 'mehl',\n",
       " 'kao',\n",
       " 'asao',\n",
       " 'nasr',\n",
       " 'asoc',\n",
       " 'kho',\n",
       " 'damm',\n",
       " 'raza',\n",
       " 'ong',\n",
       " 'pham',\n",
       " 'hupp',\n",
       " 'feng',\n",
       " 'mikx',\n",
       " 'ruma',\n",
       " 'sume',\n",
       " 'saha',\n",
       " 'hoth',\n",
       " 'euwe',\n",
       " 'deeb',\n",
       " 'koga',\n",
       " 'xia',\n",
       " 'onur',\n",
       " 'yih',\n",
       " 'hoek',\n",
       " 'winn',\n",
       " 'feik',\n",
       " 'zina',\n",
       " 'ihre',\n",
       " 'kok',\n",
       " 'arko',\n",
       " 'kcc',\n",
       " 'salo',\n",
       " 'goaz',\n",
       " 'mich',\n",
       " 'leao',\n",
       " 'braz',\n",
       " 'kahl',\n",
       " 'orme',\n",
       " 'ducy',\n",
       " 'uguz',\n",
       " 'kabi',\n",
       " 'pepe',\n",
       " 'ayas',\n",
       " 'ueki',\n",
       " 'gelb',\n",
       " 'graz',\n",
       " 'alfi',\n",
       " 'ewen',\n",
       " 'okui',\n",
       " 'symp',\n",
       " 'zene',\n",
       " 'fong',\n",
       " 'waki',\n",
       " 'dinh',\n",
       " 'snus',\n",
       " 'dans',\n",
       " 'bonn',\n",
       " 'rabe',\n",
       " 'kulk',\n",
       " 'choi',\n",
       " 'eick',\n",
       " 'solt',\n",
       " 'cato',\n",
       " 'weik',\n",
       " 'deng',\n",
       " 'avci',\n",
       " 'chiu',\n",
       " 'kock',\n",
       " 'sood',\n",
       " 'soto',\n",
       " 'otol',\n",
       " 'eber',\n",
       " 'bik',\n",
       " 'kiem',\n",
       " 'seto',\n",
       " 'dijk',\n",
       " 'pls',\n",
       " 'nys',\n",
       " 'kono',\n",
       " 'saf',\n",
       " 'veeh',\n",
       " 'eady',\n",
       " 'uslu',\n",
       " 'paju',\n",
       " 'outl',\n",
       " 'ghez',\n",
       " 'evid',\n",
       " 'ayer',\n",
       " 'arq',\n",
       " 'brox',\n",
       " 'kalk',\n",
       " 'begg',\n",
       " 'minh',\n",
       " 'aziz',\n",
       " 'oro',\n",
       " 'nutr',\n",
       " 'zhu',\n",
       " 'gebo',\n",
       " 'tsai',\n",
       " 'sepe',\n",
       " 'ohl',\n",
       " 'haan',\n",
       " 'cahn',\n",
       " 'zeng',\n",
       " 'wada',\n",
       " 'zeza',\n",
       " 'hous',\n",
       " 'hsu',\n",
       " 'berl',\n",
       " 'fiho',\n",
       " 'uzel',\n",
       " 'arai',\n",
       " 'amer',\n",
       " 'asma',\n",
       " 'xue',\n",
       " 'ype',\n",
       " 'seow',\n",
       " 'cano',\n",
       " 'paus',\n",
       " 'jung',\n",
       " 'fava',\n",
       " 'haim',\n",
       " 'munk',\n",
       " 'zahn',\n",
       " 'tura',\n",
       " 'sato',\n",
       " 'koma',\n",
       " 'jde',\n",
       " 'rios',\n",
       " 'hoz',\n",
       " 'cui',\n",
       " 'vape',\n",
       " 'zur',\n",
       " 'swed',\n",
       " 'kwok',\n",
       " 'aviv',\n",
       " 'lisi',\n",
       " 'lynd',\n",
       " 'suda',\n",
       " 'dios',\n",
       " 'kepa',\n",
       " 'esch',\n",
       " 'ochi',\n",
       " 'arno',\n",
       " 'koka']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce722989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c3fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd0f14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()\n",
    "document.add_paragraph(doc)\n",
    "\n",
    "document.save(f'C:/Users/chenn/Desktop/wbmissing/{filename}.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55543757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
